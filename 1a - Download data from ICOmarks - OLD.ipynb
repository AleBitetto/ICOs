{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4e15f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from utils import get_chromedriver, get_icos_list_by_category, adjust_date, eval_duration, scrape_info_icomarks\n",
    "from utils import extract_scaping_icomarks, summary_stats, format_columns\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from soup2dict import convert\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import sys\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b7e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMEDRIVER_PATH = r\"C:\\Users\\Alessandro Bitetto\\Downloads\\UniPV\\ICOs\\WebDriver\\chromedriver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "045f2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set folders\n",
    "CHECKPOINT_FOLDER = '.\\\\Checkpoints'\n",
    "RESULTS_FOLDER = '.\\\\Results'\n",
    "ICOMARKS_CATEG_FOLDER=os.path.join(CHECKPOINT_FOLDER, 'Icomarks_category')\n",
    "ICOMARKS_FOLDER=os.path.join(CHECKPOINT_FOLDER, 'Icomarks')\n",
    "\n",
    "if not os.path.exists(CHECKPOINT_FOLDER):\n",
    "    os.makedirs(CHECKPOINT_FOLDER)\n",
    "if not os.path.exists(RESULTS_FOLDER):\n",
    "    os.makedirs(RESULTS_FOLDER)\n",
    "if not os.path.exists(ICOMARKS_CATEG_FOLDER):\n",
    "    os.makedirs(ICOMARKS_CATEG_FOLDER)\n",
    "if not os.path.exists(ICOMARKS_FOLDER):\n",
    "    os.makedirs(ICOMARKS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf85257",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_DOMAIN = \".ai\"      # replace the old domani \".com\", changed after first run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e71a1",
   "metadata": {},
   "source": [
    "## Get ICOs url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd0676c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alessandro Bitetto\\AppData\\Local\\Temp\\ipykernel_13468\\1522410269.py:16: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  category[['Category', 'Count']] = category['Category'].str.split('(', 1, expand=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_ref</th>\n",
       "      <th>Category</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial-intelligence</td>\n",
       "      <td>AI</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>art</td>\n",
       "      <td>Art</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banking</td>\n",
       "      <td>Banking</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>big-data</td>\n",
       "      <td>Big Data</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business-services</td>\n",
       "      <td>Business</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>charity</td>\n",
       "      <td>Charity</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>communication</td>\n",
       "      <td>Communication</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cryptocurrency</td>\n",
       "      <td>Cryptocurrency</td>\n",
       "      <td>3028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>defi</td>\n",
       "      <td>DeFi</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>education</td>\n",
       "      <td>Education</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>electronics</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>energy</td>\n",
       "      <td>Energy</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>exchange-launchpad</td>\n",
       "      <td>Exchange &amp; Launchpad</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>casino-gambling</td>\n",
       "      <td>Gambling</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>health</td>\n",
       "      <td>Health</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>infrastructure</td>\n",
       "      <td>Infrastructure</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>internet</td>\n",
       "      <td>Internet</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>investment</td>\n",
       "      <td>Investment</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>legal</td>\n",
       "      <td>Legal</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>marketing-agency</td>\n",
       "      <td>Marketing Agency</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>media</td>\n",
       "      <td>Media</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>other</td>\n",
       "      <td>Other</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>platform</td>\n",
       "      <td>Platform</td>\n",
       "      <td>3602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>real-estate</td>\n",
       "      <td>Real estate</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>smart-contract</td>\n",
       "      <td>Smart Contract</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>software</td>\n",
       "      <td>Software</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sports</td>\n",
       "      <td>Sports</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tourism</td>\n",
       "      <td>Tourism</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>virtual-reality</td>\n",
       "      <td>Virtual Reality</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    url_ref               Category  Count\n",
       "0   artificial-intelligence                    AI     540\n",
       "1                       art                   Art     104\n",
       "2                   banking               Banking     647\n",
       "3                  big-data              Big Data     412\n",
       "4         business-services              Business    1346\n",
       "5                   charity               Charity     159\n",
       "6             communication         Communication     451\n",
       "7            cryptocurrency        Cryptocurrency    3028\n",
       "8                      defi                  DeFi     557\n",
       "9                 education             Education     219\n",
       "10              electronics           Electronics     102\n",
       "11                   energy                Energy     202\n",
       "12            entertainment         Entertainment     671\n",
       "13       exchange-launchpad  Exchange & Launchpad     148\n",
       "14          casino-gambling              Gambling     205\n",
       "15                   health                Health     315\n",
       "16           infrastructure        Infrastructure     565\n",
       "17                 internet              Internet     574\n",
       "18               investment            Investment    1196\n",
       "19                    legal                 Legal      95\n",
       "20            manufacturing         Manufacturing     162\n",
       "21         marketing-agency      Marketing Agency       8\n",
       "22                    media                 Media     404\n",
       "23                    other                 Other     441\n",
       "24                 platform              Platform    3602\n",
       "25              real-estate           Real estate     262\n",
       "26                   retail                Retail     315\n",
       "27           smart-contract        Smart Contract     802\n",
       "28                 software              Software     793\n",
       "29                   sports                Sports     169\n",
       "30                  tourism               Tourism     199\n",
       "31                  unknown               Unknown      16\n",
       "32          virtual-reality       Virtual Reality     161"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAIN_PAGE = \"https://icomarks.com/\"                # to be added to single ICO url\n",
    "CATEGORY_PAGE = \"https://icomarks.com/icos/\"       # used to query the category to be downloaded\n",
    "\n",
    "# get html\n",
    "page = requests.get(CATEGORY_PAGE.replace(\".com\", NEW_DOMAIN))\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# extract list of categories\n",
    "tag = soup.find_all('div', class_=\"icoTop__selects\", recursive=True)\n",
    "conv_dict = convert(tag)\n",
    "while conv_dict['div'][0]['@class'][0] != 'icoTop__selects':\n",
    "    conv_dict = conv_dict['div'][0]\n",
    "category_list = conv_dict['div'][0]['form'][0]['select'][0]['option']\n",
    "category = pd.DataFrame([(v['@value'], v['#text']) for v in category_list if '@value' in v.keys()],\n",
    "                        columns =['url_ref', 'Category'])\n",
    "category[['Category', 'Count']] = category['Category'].str.split('(', 1, expand=True)\n",
    "category['Count'] = category['Count'].apply(lambda x: int(x.replace(')', '')))\n",
    "display(category)\n",
    "\n",
    "platform_list=conv_dict['div'][0]['form'][0]['select'][1]['option']\n",
    "platform = pd.DataFrame([(v['@value'], v['#text']) for v in platform_list if '@value' in v.keys()],\n",
    "                        columns =['url_ref', 'Platform'])\n",
    "\n",
    "status_list=conv_dict['div'][0]['form'][0]['select'][2]['option']\n",
    "status = pd.DataFrame([(v['@value'], v['#text']) for v in status_list if '@value' in v.keys()],\n",
    "                        columns =['url_ref', 'Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aaeaa54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Downloading: AI   (540 expected) 1 / 33\n",
      "   - Scrolling down...Reloaded\n",
      "   - Downloading html...Reloaded\n",
      "   - Parsing info...Reloaded  OK\n",
      "     Elapsed time: 0:01:38\n",
      "\n",
      "- Downloading: Art   (104 expected) 2 / 33\n",
      "   - Scrolling down...Reloaded\n",
      "   - Downloading html...Reloaded\n",
      "   - Parsing info...Reloaded  OK\n",
      "     Elapsed time: 0:00:22\n",
      "\n",
      "- Downloading: Banking   (647 expected) 3 / 33\n",
      "   - Scrolling down...Reloaded\n",
      "   - Downloading html...Reloaded\n",
      "   - Parsing info...Reloaded     ####### warning, expected number of elements (647) mismatch. Found 160\n",
      "     Elapsed time: 0:00:28\n",
      "\n",
      "- Downloading: Big Data   (412 expected) 4 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:01:12\n",
      "\n",
      "- Downloading: Business   (1346 expected) 5 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:04:09\n",
      "\n",
      "- Downloading: Charity   (159 expected) 6 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:32\n",
      "\n",
      "- Downloading: Communication   (451 expected) 7 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:01:28\n",
      "\n",
      "- Downloading: Cryptocurrency   (3028 expected) 8 / 33\n",
      "   - Scrolling down, Parsing info and Downloading html for each split... 143 / 143\n",
      "\n",
      "   ####### warning, expected number of elements (3028) mismatch. Found 2878\n",
      "     Elapsed time: 0:26:06\n",
      "\n",
      "- Downloading: DeFi   (557 expected) 9 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...   ####### warning, expected number of elements (557) mismatch. Found 558\n",
      "     Elapsed time: 0:01:40\n",
      "\n",
      "- Downloading: Education   (219 expected) 10 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:41\n",
      "\n",
      "- Downloading: Electronics   (102 expected) 11 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:25\n",
      "\n",
      "- Downloading: Energy   (202 expected) 12 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:44\n",
      "\n",
      "- Downloading: Entertainment   (671 expected) 13 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:02:02\n",
      "\n",
      "- Downloading: Exchange & Launchpad   (148 expected) 14 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:34\n",
      "\n",
      "- Downloading: Gambling   (205 expected) 15 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:41\n",
      "\n",
      "- Downloading: Health   (315 expected) 16 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:01:04\n",
      "\n",
      "- Downloading: Infrastructure   (565 expected) 17 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:01:43\n",
      "\n",
      "- Downloading: Internet   (574 expected) 18 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:01:51\n",
      "\n",
      "- Downloading: Investment   (1196 expected) 19 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:03:42\n",
      "\n",
      "- Downloading: Legal   (95 expected) 20 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:22\n",
      "\n",
      "- Downloading: Manufacturing   (162 expected) 21 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:38\n",
      "\n",
      "- Downloading: Marketing Agency   (8 expected) 22 / 33\n",
      "   - Scrolling down...SKIPPED\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:10\n",
      "\n",
      "- Downloading: Media   (404 expected) 23 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:01:19\n",
      "\n",
      "- Downloading: Other   (441 expected) 24 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:01:25\n",
      "\n",
      "- Downloading: Platform   (3602 expected) 25 / 33\n",
      "   - Scrolling down, Parsing info and Downloading html for each split... 143 / 143\n",
      "\n",
      "   ####### warning, expected number of elements (3602) mismatch. Found 3377\n",
      "     Elapsed time: 0:23:46\n",
      "\n",
      "- Downloading: Real estate   (262 expected) 26 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:48\n",
      "\n",
      "- Downloading: Retail   (315 expected) 27 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:55\n",
      "\n",
      "- Downloading: Smart Contract   (802 expected) 28 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...   ####### warning, expected number of elements (802) mismatch. Found 803\n",
      "     Elapsed time: 0:02:16\n",
      "\n",
      "- Downloading: Software   (793 expected) 29 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:02:13\n",
      "\n",
      "- Downloading: Sports   (169 expected) 30 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:31\n",
      "\n",
      "- Downloading: Tourism   (199 expected) 31 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:36\n",
      "\n",
      "- Downloading: Unknown   (16 expected) 32 / 33\n",
      "   - Scrolling down...SKIPPED\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:08\n",
      "\n",
      "- Downloading: Virtual Reality   (161 expected) 33 / 33\n",
      "   - Scrolling down...OK\n",
      "   - Downloading html...OK\n",
      "   - Parsing info...OK\n",
      "     Elapsed time: 0:00:32\n",
      "\n",
      "\n",
      "Total elapsed time: 1:26:41\n",
      "\n",
      "Data saved in  .\\Results\\01a_ICOmarks_ico_list_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# apply category in search query and get ICO list\n",
    "SPLIT_BY = 'platform'   # 'status' or 'platform', used to split download for categories with more than 1500 entries\n",
    "RELOAD_PKL = True\n",
    "\n",
    "cat_list = pd.DataFrame(columns=['Category', 'url', 'NViews', 'VerifiedEmailDummy', 'IsSTODummy', 'IsIEODummy',\n",
    "                                 'Status', 'StartDate', 'EndDate'])\n",
    "\n",
    "download_date=datetime.datetime.now().strftime(\"%d/%m/%Y\")\n",
    "tot_time = 0\n",
    "for index, row in category.iterrows():\n",
    "    \n",
    "    url_categ = row['url_ref']\n",
    "    expected_count = row['Count']\n",
    "    categ = row['Category']\n",
    "    count = row['Count']\n",
    "    \n",
    "    pkl_path=os.path.join(ICOMARKS_CATEG_FOLDER, url_categ+'.pkl').replace('|', '')\n",
    "    \n",
    "    print(f'\\n- Downloading: {categ}  ({expected_count} expected) {index + 1} / {len(category)}')\n",
    "    \n",
    "    try:\n",
    "        if not RELOAD_PKL or not os.path.exists(pkl_path):\n",
    "            start = timer()\n",
    "            # decide if splitting the download by filtering each platform (longer list may crash when scrolling down)\n",
    "            if count > 1500:\n",
    "                if SPLIT_BY == 'status':\n",
    "                    split_df = status\n",
    "                elif SPLIT_BY == 'platform':\n",
    "                    split_df = platform\n",
    "\n",
    "                temp_list = pd.DataFrame()\n",
    "                for i, filter_row in split_df.iterrows():\n",
    "\n",
    "                    print(f'   - Scrolling down, Parsing info and Downloading html for each split... {i+1} / {len(split_df)}', end='\\r')\n",
    "\n",
    "                    filter_val = filter_row['url_ref']\n",
    "                    url_filter = f'?{SPLIT_BY}={filter_val}&whitelist=&kyc=&bounty=&mvp=&email_confirmed='\n",
    "                    url = urljoin(CATEGORY_PAGE.replace(\".com\", NEW_DOMAIN), url_categ+url_filter)\n",
    "\n",
    "                    tt = get_icos_list_by_category(url, categ, CHROMEDRIVER_PATH, MAIN_PAGE, NEW_DOMAIN, split=True)\n",
    "                    temp_list = pd.concat([temp_list, tt])\n",
    "                temp_list = temp_list.drop_duplicates()\n",
    "                print('\\n')\n",
    "            else:\n",
    "                url = urljoin(CATEGORY_PAGE.replace(\".com\", NEW_DOMAIN), url_categ)\n",
    "                temp_list = get_icos_list_by_category(url, categ, CHROMEDRIVER_PATH, MAIN_PAGE, NEW_DOMAIN)\n",
    "            eval_time = datetime.timedelta(seconds=round(timer()-start)).total_seconds()\n",
    "\n",
    "            # save pkl\n",
    "            joblib.dump({'temp_list': temp_list,\n",
    "                         'eval_time': eval_time}, pkl_path, compress=('lzma', 3))\n",
    "        else:\n",
    "            print('   - Scrolling down...Reloaded')\n",
    "            print('   - Downloading html...Reloaded')\n",
    "            print('   - Parsing info...Reloaded', end='  ')\n",
    "            rr = joblib.load(pkl_path)\n",
    "            temp_list = rr['temp_list']\n",
    "            eval_time = rr['eval_time']\n",
    "\n",
    "        tot_time += eval_time\n",
    "        temp_list['ListDownloadedOn']=download_date\n",
    "        cat_list = pd.concat([cat_list, temp_list])\n",
    "\n",
    "        if temp_list.shape[0] != expected_count:\n",
    "            print('   ####### warning, expected number of elements (' + str(expected_count) + ') mismatch. Found ' + str(temp_list.shape[0]))\n",
    "        else:\n",
    "            print('OK')\n",
    "\n",
    "        print('     Elapsed time:', str(datetime.timedelta(seconds=round(eval_time))))\n",
    "    except:\n",
    "        print('######## ERROR')\n",
    "        \n",
    "# save results\n",
    "cat_list.to_csv(os.path.join(RESULTS_FOLDER,'01a_ICOmarks_ico_list_raw.csv'), index=False, sep=';')    \n",
    "    \n",
    "print('\\n\\nTotal elapsed time:', str(datetime.timedelta(seconds=round(tot_time))))\n",
    "print('\\nData saved in ', os.path.join(RESULTS_FOLDER,'01a_ICOmarks_ico_list_raw.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a32b8",
   "metadata": {},
   "source": [
    "### Check downloaded list and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374ec979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Url with multiple entries found. Keeping single information only\n",
      "    - https://icomarks.ai/ico/ins: Multiple status found: ['Trading' 'Ended']. Keeping 'Ended'\n",
      "    - https://icomarks.ai/ico/unifox: Multiple status found: ['Pre-Sale Ended' 'Ended']. Keeping 'Ended'\n",
      "\n",
      "-- Total ICOs found: 8348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ended</th>\n",
       "      <td>4998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upcoming</th>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trading</th>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-Sale Ended</th>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Active</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-Sale</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Status\n",
       "Ended             4998\n",
       "Upcoming          1975\n",
       "Trading            697\n",
       "Pre-Sale Ended     444\n",
       "Active             164\n",
       "Pre-Sale            70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved in  .\\Results\\01b_ICOmarks_ico_list_adjusted.csv\n"
     ]
    }
   ],
   "source": [
    "cat_list=pd.read_csv(os.path.join(RESULTS_FOLDER,'01a_ICOmarks_ico_list_raw.csv'), sep=';')\n",
    "\n",
    "cat_list.drop_duplicates(inplace=True)\n",
    "\n",
    "# adjust dates\n",
    "cat_list['StartDate']=cat_list['StartDate'].map(adjust_date)\n",
    "cat_list['EndDate']=cat_list['EndDate'].map(adjust_date)\n",
    "\n",
    "# find url with multiple entries (due to IEO/STO) and keep all categories and minimum start date and max end date\n",
    "multiple_url=cat_list[['url', 'NViews']].drop_duplicates()['url'].value_counts().to_frame().reset_index().query('url > 1')['index']\n",
    "if len(multiple_url) > 0:\n",
    "    \n",
    "    print('\\n-- Url with multiple entries found. Keeping single information only')\n",
    "    new_df=pd.DataFrame(columns=cat_list.columns)\n",
    "    for t_url in multiple_url:\n",
    "        t_df=cat_list[cat_list['url']==t_url].copy()\n",
    "\n",
    "        status=t_df['Status'].value_counts().index[0]\n",
    "        if t_df['Status'].nunique() > 1:\n",
    "            u_val=t_df['Status'].unique()\n",
    "            if 'Ended' in u_val:\n",
    "                status='Ended'\n",
    "            if 'Active' in u_val:\n",
    "                status='Active'\n",
    "            print(f\"    - {t_url}: Multiple status found: {u_val}. Keeping '{status}'\")\n",
    "\n",
    "        try:\n",
    "            start_date=pd.to_datetime(t_df['StartDate'].loc[lambda x : x != 'TBA'], infer_datetime_format=True).min().strftime('%d %b %Y')\n",
    "        except:\n",
    "            start_date=t_df['StartDate'].unique()[0]\n",
    "        try:\n",
    "            end_date=pd.to_datetime(t_df['EndDate'].loc[lambda x : x != 'TBA'], infer_datetime_format=True).max().strftime('%d %b %Y')\n",
    "        except:\n",
    "            end_date=t_df['EndDate'].unique()[0]\n",
    "\n",
    "        add_df=pd.DataFrame({'Category': t_df['Category'].unique(),\n",
    "                            'url': t_url,\n",
    "                            'NViews': t_df['NViews'].max(),\n",
    "                            'VerifiedEmailDummy': t_df['VerifiedEmailDummy'].max(),\n",
    "                            'IsSTODummy': t_df['IsSTODummy'].max(),\n",
    "                            'IsIEODummy': t_df['IsIEODummy'].max(),\n",
    "                            'Status': status,\n",
    "                            'StartDate': start_date,\n",
    "                            'EndDate': end_date,\n",
    "                            'ListDownloadedOn': t_df['ListDownloadedOn'].values[0]})\n",
    "\n",
    "        new_df=pd.concat([new_df, add_df])\n",
    "        \n",
    "    cat_list=cat_list[~cat_list['url'].isin(multiple_url)]\n",
    "    cat_list=pd.concat([cat_list, new_df]) \n",
    "\n",
    "# get dummy for category\n",
    "cat_list['Category']=cat_list['Category'].str.replace(' ', '')\n",
    "cat_dummy=pd.concat([cat_list['url'], pd.get_dummies(cat_list['Category'], drop_first=False, prefix='Category', prefix_sep='')], axis=1)\n",
    "cat_dummy=cat_dummy.groupby('url').sum()\n",
    "cat_dummy.columns=cat_dummy.columns+'Dummy'\n",
    "if cat_dummy.max().max() != 1:\n",
    "    print('\\n ### \"Category\" dummy variable has value greater than 1')\n",
    "cat_dummy.reset_index(inplace=True)\n",
    "\n",
    "# evaluate duration\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/kaizen-coin', 'StartDate']='18 Aug 2017'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/curveblock', 'EndDate']='31-mar-19'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/0chain', 'EndDate']='19-feb-18'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/hunibit', 'StartDate']='21 apr 2019'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/hunibit', 'EndDate']='03 may 2019'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/clearaid', 'EndDate']='01 may 2019'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/ultrashares', 'StartDate']='23 apr 2018'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/ultrashares', 'EndDate']='30 jun 2018'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/dentix', 'StartDate']='01-mar-18'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/eos', 'EndDate']='04 jun 2018'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/mundus', 'StartDate']='31 aug 2017'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/mundus', 'EndDate']='30 oct 2017'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/vr-park', 'StartDate']='24 aug 2019'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/vr-park', 'EndDate']='17 apr 2020'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/goldminecoin', 'EndDate']='15 mar 2018'\n",
    "cat_list.loc[cat_list['url'] == 'https://icomarks.ai/ico/horsechain', 'EndDate']='14 Jul 2019'\n",
    "cat_list['LogDurationDays']=cat_list.apply(eval_duration, axis=1)\n",
    "move_col = cat_list.pop('LogDurationDays')\n",
    "cat_list.insert(cat_list.columns.get_loc(\"EndDate\")+1, 'LogDurationDays', move_col)\n",
    "check_error=cat_list[cat_list['LogDurationDays'] < 0][['url', 'Status', 'StartDate', 'EndDate']].drop_duplicates()\n",
    "if len(check_error):\n",
    "    print(f'\\n-- {len(check_error)} rows with error in \"LogDurationDays\":')\n",
    "    display(check_error['Status'].value_counts().to_frame())\n",
    "    check_error.to_csv(os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_adjusted_DurationError.csv'), index=False, sep=';')\n",
    "    print('Log saved in ', os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_adjusted_DurationError.csv'))\n",
    "    \n",
    "\n",
    "# create final dataset\n",
    "cat_list=cat_list.drop(columns='Category').drop_duplicates()\n",
    "cat_list=cat_list.merge(cat_dummy, on='url', how='left')\n",
    "move_col = cat_list.pop('ListDownloadedOn')\n",
    "cat_list.insert(cat_list.columns.get_loc(\"url\")+1, 'ListDownloadedOn', move_col)\n",
    "\n",
    "if cat_list['url'].nunique() != cat_list.shape[0]:\n",
    "    print('\\n ##### Unique urls do not match number of rows')\n",
    "\n",
    "print('\\n-- Total ICOs found:', cat_list['url'].nunique())\n",
    "display(cat_list['Status'].value_counts().to_frame())\n",
    "    \n",
    "# save csv\n",
    "cat_list.to_csv(os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_adjusted.csv'), index=False, sep=';')\n",
    "print('\\nData saved in ', os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_adjusted.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f827f1",
   "metadata": {},
   "source": [
    "### Compare with previous download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "727eea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Compare with previous download:\n",
      "  8032 common url found\n",
      "  247 old url missing\n",
      "  316 new url found\n",
      "      *** List with new url only saved in  .\\Results\\01b_ICOmarks_ico_list_new_only.csv\n",
      "\n",
      "\n",
      "-- 257 mismatch on common url found:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mismatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>different Date</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different Status| different Date</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different Dummy</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different Status</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different Dummy| different Status| different Date</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different Dummy| different Status</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different Dummy| different Date</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mismatch\n",
       " different Date                                          199\n",
       " different Status| different Date                         37\n",
       " different Dummy                                          10\n",
       " different Status                                          7\n",
       " different Dummy| different Status| different Date         2\n",
       " different Dummy| different Status                         1\n",
       " different Dummy| different Date                           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log saved in  .\\Results\\01b_ICOmarks_ico_list_adjusted_difference_with_OLD.csv\n",
      "\n",
      "-- New information for ICOs is kept and missing old ICOs are added\n",
      "\n",
      "-- Total ICOs found: 8595\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ended</th>\n",
       "      <td>5123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upcoming</th>\n",
       "      <td>2054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trading</th>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-Sale Ended</th>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Active</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-Sale</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Status\n",
       "Ended             5123\n",
       "Upcoming          2054\n",
       "Trading            727\n",
       "Pre-Sale Ended     454\n",
       "Active             167\n",
       "Pre-Sale            70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved in  .\\Results\\01b_ICOmarks_ico_list_merged.csv\n"
     ]
    }
   ],
   "source": [
    "new = pd.read_csv(os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_adjusted.csv'), sep=';')\n",
    "old = pd.read_csv(os.path.join(RESULTS_FOLDER, 'OLD 01b_ICOmarks_ico_list_adjusted.csv'), sep=';')\n",
    "old['url'] = old['url'].str.replace(\".com\", NEW_DOMAIN, regex=False)\n",
    "\n",
    "url_common = set(new['url']) & set(old['url'])\n",
    "url_new_only = set(new['url']) - set(old['url'])\n",
    "url_old_only = set(old['url']) - set(new['url'])\n",
    "print('-- Compare with previous download:')\n",
    "print(f'  {len(url_common)} common url found')\n",
    "print(f'  {len(url_old_only)} old url missing')\n",
    "print(f'  {len(url_new_only)} new url found')\n",
    "new[new['url'].isin(url_new_only)].to_csv(os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_new_only.csv'), index=False, sep=';')\n",
    "print('      *** List with new url only saved in ', os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_new_only.csv'))\n",
    "\n",
    "common_diff = pd.DataFrame()\n",
    "for url in url_common:\n",
    "    new_t = new[new['url']==url]\n",
    "    old_t = old[old['url']==url]\n",
    "    \n",
    "    diff=''\n",
    "    \n",
    "    if (new_t['IsSTODummy'].values[0] != old_t['IsSTODummy'].values[0] or\n",
    "        new_t['IsIEODummy'].values[0] != old_t['IsIEODummy'].values[0] or\n",
    "        new_t['VerifiedEmailDummy'].values[0] != old_t['VerifiedEmailDummy'].values[0]):\n",
    "        diff += '| different Dummy'\n",
    "\n",
    "    if new_t['Status'].values[0] != old_t['Status'].values[0]:\n",
    "        diff += '| different Status'\n",
    "    \n",
    "    if (new_t['LogDurationDays'].values[0] != old_t['LogDurationDays'].values[0] and\n",
    "        ~new_t['LogDurationDays'].isna().values[0] and\n",
    "        ~old_t['LogDurationDays'].isna().values[0]):\n",
    "        diff += '| different Date'\n",
    "    \n",
    "    if len(diff) > 0:\n",
    "        common_diff = pd.concat([common_diff, pd.DataFrame({'url': url, 'mismatch': diff[1:]}, index=[0])])\n",
    "        \n",
    "print(f'\\n\\n-- {len(common_diff)} mismatch on common url found:')\n",
    "display(common_diff['mismatch'].value_counts().to_frame())\n",
    "\n",
    "common_diff.to_csv(os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_adjusted_difference_with_OLD.csv'), index=False, sep=';')\n",
    "print('\\nLog saved in ', os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_adjusted_difference_with_OLD.csv'))\n",
    "\n",
    "cat_list = pd.concat([old[old['url'].isin(url_old_only)], new[new['url'].isin(url_common | url_new_only)]]).reset_index(drop=True)\n",
    "if len(cat_list) != cat_list['url'].nunique():\n",
    "    print('######### duplicates in \"cat_list\"')\n",
    "print('\\n-- New information for ICOs is kept and missing old ICOs are added')\n",
    "print('\\n-- Total ICOs found:', cat_list['url'].nunique())\n",
    "display(cat_list['Status'].value_counts().to_frame())\n",
    "\n",
    "# save csv\n",
    "cat_list.to_csv(os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_merged.csv'), index=False, sep=';')\n",
    "print('\\nData saved in ', os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_merged.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13017da",
   "metadata": {},
   "source": [
    "## Scrape information from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f6c92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_ROOT='https://icomarks.com/ico/'    # will be removed from url to save pickle in ICOMARKS_FOLDER\n",
    "RELOAD_PKL=True\n",
    "SKIP_MISSING=False     # if True skip attempt to scrape missing pickles\n",
    "\n",
    "if not os.path.exists(ICOMARKS_FOLDER):\n",
    "    os.makedirs(ICOMARKS_FOLDER)\n",
    "\n",
    "cat_list=pd.read_csv(os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_merged.csv'), sep=';')\n",
    "url_mismatch=pd.read_csv(os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_adjusted_difference_with_OLD.csv'), sep=';')['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8ab4387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Scraping: 8595 / 8595   last interaction: 08/03/2024 18:29:23\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ScrapeStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OK</th>\n",
       "      <td>8595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ScrapeStatus\n",
       "OK          8595"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Total elapsed time: 1 day, 11:08:23\n",
      "\n",
      "Data saved in .\\Checkpoints\\scrape_df_raw.pkl\n"
     ]
    }
   ],
   "source": [
    "scrape_df=pd.DataFrame()\n",
    "for index, row in cat_list.iterrows():\n",
    "    \n",
    "    print(f'- Scraping: {str(index + 1)} / {len(cat_list)}   last interaction: {datetime.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}', end='\\r')\n",
    "    \n",
    "    url=row['url']\n",
    "    save_path=os.path.join(ICOMARKS_FOLDER, url.replace(URL_ROOT.replace(\".com\", NEW_DOMAIN), '')+'.json').replace('|', '')\n",
    "    \n",
    "    if not RELOAD_PKL or not os.path.exists(save_path) or url in url_mismatch:\n",
    "    \n",
    "        if SKIP_MISSING and not os.path.exists(save_path):\n",
    "            add_row=pd.DataFrame({'url': url, 'ScrapeStatus': 'ERROR'}, index=[0])\n",
    "            scrape_df=pd.concat([scrape_df, add_row])\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            start = timer()\n",
    "            add_row=scrape_info_icomarks(url=url, chromedriver_path=CHROMEDRIVER_PATH, skip_social=False, skip_price=False)\n",
    "            add_row.insert(1, 'ScrapeStatus', 'OK')\n",
    "            add_row['PklPath']=save_path\n",
    "            add_row['TotTimeSec']=datetime.timedelta(seconds=round(timer()-start)).total_seconds()\n",
    "            add_row.to_json(save_path, orient='table')\n",
    "        except:\n",
    "            add_row=pd.DataFrame({'url': url, 'ScrapeStatus': 'ERROR'}, index=[0])\n",
    "    \n",
    "    else:\n",
    "        add_row=pd.read_json(save_path, orient='table')\n",
    "        # re-format nested dataframe from json schema\n",
    "        add_row['InfoBlock']=[pd.DataFrame(add_row['InfoBlock'][0])]\n",
    "        if 'TeamBlock' in add_row.columns:\n",
    "            add_row['TeamBlock']=[pd.DataFrame(add_row['TeamBlock'][0])]\n",
    "        if 'SocialBlock' in add_row.columns:\n",
    "            social_df=pd.DataFrame(add_row['SocialBlock'][0][0]['stats'])\n",
    "            series_dict={}\n",
    "            for k in add_row['SocialBlock'][0][0]['timeseries'].keys():\n",
    "                series_dict[k]=pd.DataFrame(add_row['SocialBlock'][0][0]['timeseries'][k])\n",
    "            add_row['SocialBlock']=[[{'stats': social_df, 'timeseries': series_dict}]]\n",
    "        if 'MarketPriceSeries' in add_row.columns:\n",
    "            add_row['MarketPriceSeries']=[pd.DataFrame(add_row['MarketPriceSeries'][0])]\n",
    "        \n",
    "    scrape_df=pd.concat([scrape_df, add_row])\n",
    "\n",
    "scrape_df.reset_index(drop=True, inplace=True)\n",
    "display(scrape_df['ScrapeStatus'].value_counts().to_frame())\n",
    "   \n",
    "print('\\n\\nTotal elapsed time:', str(datetime.timedelta(seconds=round(scrape_df['TotTimeSec'].sum()))))\n",
    "\n",
    "# save\n",
    "scrape_df['url'] = scrape_df['url'].str.replace(\".com\", NEW_DOMAIN, regex=False)\n",
    "pkl_path=os.path.join(CHECKPOINT_FOLDER, 'scrape_df_raw.pkl')\n",
    "joblib.dump(scrape_df, pkl_path, compress=('lzma', 3))\n",
    "print(f'\\nData saved in {pkl_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac6c3f",
   "metadata": {},
   "source": [
    "## Format scraped information and save final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb29d99",
   "metadata": {},
   "source": [
    "#### Download FX rates from Finance.yahoo.com and Investing.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2b65d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved in  .\\Data and papers\\FX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# data from Investing.com must be downloaded manually. See utils.py\n",
    "\n",
    "for tick in ['ETH-USD', 'BNB-USD', 'USDT-USD', 'BTC-USD', 'XLM-USD', 'TRX-USD', 'BUSD-USD', 'KRW-USD', 'NEO-USD', 'MATIC-USD',\n",
    "             'USDC-USD', 'WAVES-USD', 'BTS-USD', 'VET-USD', 'ICX-USD', 'LNC-USD', 'WETH-USD', 'DOT-USD', 'AVAX-USD', 'AV-USD']:\n",
    "    \n",
    "    # download new data\n",
    "    data = yf.download(tick, interval='1mo', period='max')\n",
    "    data = data.reset_index()\n",
    "\n",
    "    # reload previous data and merge\n",
    "    dd = pd.read_csv(os.path.join('.\\\\Data and papers\\\\FX', tick+'.csv'), parse_dates=['Date'])\n",
    "    common_date = set(data['Date']) & set(dd['Date'])\n",
    "    recover_date = set(dd['Date']) - set(data['Date'])\n",
    "    merge_data = pd.concat([dd[dd['Date'].isin(recover_date)], data])\n",
    "    merge_data = merge_data.sort_values(by='Date', ascending=True)\n",
    "\n",
    "    merge_data.to_csv(os.path.join('.\\\\Data and papers\\\\FX', tick+'.csv'), index=False)\n",
    "    \n",
    "print(f'\\nData saved in ', '.\\\\Data and papers\\\\FX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46eb1491",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----######   Extracting information from raw scraped data   ######----\n",
      "\n",
      "   - Processing 8595 / 8595\n",
      "   - Data saved in .\\Checkpoints\\scrape_df_extracted.pkl\n",
      "\n",
      "\n",
      "\n",
      "----######   Formatting columns   ######----\n",
      "\n",
      "** Formatting \"FundRaised\"\n",
      "\n",
      "** Formatting \"Country\"\n",
      "- Mapped countries with low accuracy:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Country_adj</th>\n",
       "      <th>country</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Grand Cayman</td>\n",
       "      <td>Grand Cayman</td>\n",
       "      <td>Cayman Islands</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Singarope</td>\n",
       "      <td>Singarope</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Singapura</td>\n",
       "      <td>Singapura</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Malte</td>\n",
       "      <td>Malte</td>\n",
       "      <td>Malta</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Nederland</td>\n",
       "      <td>Nederland</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Melta</td>\n",
       "      <td>Melta</td>\n",
       "      <td>Malta</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>anada</td>\n",
       "      <td>anada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Tunis</td>\n",
       "      <td>Tunis</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>St Vincent</td>\n",
       "      <td>St Vincent</td>\n",
       "      <td>Saint Vincent and the Grenadines</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Per</td>\n",
       "      <td>Per</td>\n",
       "      <td>Peru</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Vietnum</td>\n",
       "      <td>Vietnum</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Cambidia</td>\n",
       "      <td>Cambidia</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Cameroun</td>\n",
       "      <td>Cameroun</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Singapure</td>\n",
       "      <td>Singapure</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country   Country_adj                           country  accuracy\n",
       "152  Grand Cayman  Grand Cayman                    Cayman Islands        73\n",
       "45      Singarope     Singarope                         Singapore        78\n",
       "235     Singapura     Singapura                         Singapore        78\n",
       "155         Malte         Malte                             Malta        80\n",
       "172     Nederland     Nederland                       Netherlands        80\n",
       "224         Melta         Melta                             Malta        80\n",
       "95         Brasil        Brasil                            Brazil        83\n",
       "154        anada        anada                            Canada        83\n",
       "264         Tunis         Tunis                           Tunisia        83\n",
       "177    St Vincent    St Vincent  Saint Vincent and the Grenadines        86\n",
       "215          Per          Per                              Peru        86\n",
       "256       Vietnum       Vietnum                           Vietnam        86\n",
       "165      Cambidia      Cambidia                          Cambodia        88\n",
       "179      Cameroun      Cameroun                          Cameroon        88\n",
       "203     Singapure     Singapure                         Singapore        89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Formatting \"SocialMedia\"\n",
      "- Counts for SocialMedia dummy:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>7963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Telegram</td>\n",
       "      <td>7185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>6115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Medium</td>\n",
       "      <td>4718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>4105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bitcointalk</td>\n",
       "      <td>3846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Reddit</td>\n",
       "      <td>3643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Github</td>\n",
       "      <td>3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linkedin</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Instagram</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discord</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Slack</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VK</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            val  count\n",
       "10      Twitter   7963\n",
       "9      Telegram   7185\n",
       "2      Facebook   6115\n",
       "6        Medium   4718\n",
       "12      Youtube   4105\n",
       "0   Bitcointalk   3846\n",
       "7        Reddit   3643\n",
       "3        Github   3269\n",
       "5      Linkedin   1250\n",
       "4     Instagram   1154\n",
       "1       Discord   1048\n",
       "8         Slack    867\n",
       "11           VK    306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Formatting \"ICOPrice\", \"IEOPrice\", \"STOPrice\"\n",
      "- Errors when parsing \"ICOPrice\", \"IEOPrice\", \"STOPrice\":\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>6520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency range error missing label-missing currency unit numeric</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing currency unit numeric</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple token or currency index</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency error float-missing currency unit numeric</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token error float-missing token unit numeric</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple token or currency index -missing currency unit numeric</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    error\n",
       "                                                     6520\n",
       "currency range error missing label-missing curr...     14\n",
       "missing currency unit numeric                          12\n",
       "multiple token or currency index                        4\n",
       "currency error float-missing currency unit numeric      2\n",
       "token error float-missing token unit numeric            1\n",
       "multiple token or currency index -missing curre...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Error log saved in .\\Results\\01c_ICOmarks_formatted_price_error_log.csv\n",
      "- 17 rows removed because currency FX rate not available\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>currency_lab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TTC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CENTS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCX</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XEM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TH</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOFGOLD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMB</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BTCM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPY</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XRP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QTUM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         currency_lab\n",
       "TTC                 1\n",
       "ET                  1\n",
       "WAN                 1\n",
       "CENTS               1\n",
       "CAD                 1\n",
       "BSCX                1\n",
       "FTM                 1\n",
       "XEM                 1\n",
       "TH                  1\n",
       "GOFGOLD             1\n",
       "RMB                 1\n",
       "BTCM                1\n",
       "JPY                 1\n",
       "GA                  1\n",
       "XRP                 1\n",
       "QTUM                1\n",
       "ADA                 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Taking closest available FX rate for 118 rows. Currency: ['ETH' 'VET' 'KRW']\n",
      "- Price available for 6503 entries\n",
      "- Price log saved in .\\Results\\01c_ICOmarks_formatted_price_log.csv\n",
      "\n",
      "** Formatting \"PreSalePrice\"\n",
      "- Errors when parsing \"PreSalePrice\":\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency range error missing label-missing currency unit numeric</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing currency unit numeric</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token error float-missing token unit numeric-missing currency unit numeric</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple token or currency index</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    error\n",
       "                                                     1765\n",
       "currency range error missing label-missing curr...     10\n",
       "missing currency unit numeric                           4\n",
       "token error float-missing token unit numeric-mi...      1\n",
       "multiple token or currency index                        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Error log saved in .\\Results\\01c_ICOmarks_formatted_PreSaleprice_error_log.csv\n",
      "- 4 rows removed because currency FX rate not available\n",
      "- Taking closest available FX rate for 28 rows. Currency: ['ETH']\n",
      "- Price available for 1761 entries\n",
      "- Price log saved in .\\Results\\01c_ICOmarks_formatted_PreSaleprice_log.csv\n",
      "\n",
      "** Formatting \"FundHardCap\" and \"FundSoftCap\"\n",
      "- Errors when parsing \"FundHardCap\" and \"FundSoftCap\":\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>7889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing currency unit numeric</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency range error missing label-missing currency unit numeric</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency range error multiple labels-missing currency unit numeric</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple token or currency index</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    error\n",
       "                                                     7889\n",
       "missing currency unit numeric                          28\n",
       "currency range error missing label-missing curr...     25\n",
       "currency range error multiple labels-missing cu...      1\n",
       "multiple token or currency index                        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Error log saved in .\\Results\\01c_ICOmarks_formatted_HardSoftCap_error_log.csv\n",
      "- 27 rows in \"only_token_df\" (with Hard/Soft Cap in tokens) skipped because of missing \"PriceUSD\"\n",
      "- 475 rows remaing in \"only_token_df\" (with Hard/Soft Cap in tokens)\n",
      "- 24 rows in \"only_currency_df\" (with Hard/Soft Cap in currency) skipped because FX rate not available\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>currency_lab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MILLION</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATRIX</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLN</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEEDO</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFTOTALSUPPLY</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USO</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOMO</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCO</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIOTECHTOKENS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOKENS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QTUM</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDAP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PXS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               currency_lab\n",
       "MILLION                   4\n",
       "MATRIX                    2\n",
       "PLN                       2\n",
       "WEEDO                     2\n",
       "OFTOTALSUPPLY             1\n",
       "USO                       1\n",
       "BCC                       1\n",
       "MATC                      1\n",
       "GC                        1\n",
       "TOMO                      1\n",
       "DCO                       1\n",
       "DTC                       1\n",
       "M                         1\n",
       "BIOTECHTOKENS             1\n",
       "TOKENS                    1\n",
       "QTUM                      1\n",
       "IDAP                      1\n",
       "PXS                       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Taking closest available FX rate for 253 rows. Currency: ['ETH' 'KRW']\n",
      "- 7359 rows remaing in \"only_currency_df\" (with Hard/Soft Cap in currency)\n",
      "- All 4 rows in \"both_df\" (with Hard/Soft Cap in currency AND token) skipped because of mismatch\n",
      "\n",
      "- Hard/Soft Cap available for 7834 entries\n",
      "- Price log saved in .\\Results\\01c_ICOmarks_formatted_HardSoftCap_log.csv\n",
      "\n",
      "** Formatting \"Platform\"\n",
      "- Unique platform found: 136\n",
      "- Unique list saved in .\\Results\\01d_ICOmarks_formatted_Platform_unique.csv\n",
      "\n",
      "** Formatting \"TokenAvailForSale\" and \"TokenTotSupply\"\n",
      "- Errors when parsing \"TokenAvailForSale\":\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>8595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  error\n",
       "   8595"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Error log saved in .\\Results\\01e_ICOmarks_formatted_TokenAvailForSale_error_log.csv\n",
      "\n",
      "** Formatting \"AcceptedCurr\"\n",
      "- Unique AcceptedCurr found: 274\n",
      "- Unique list saved in .\\Results\\01f_ICOmarks_formatted_AcceptedCurr_unique.csv\n",
      "\n",
      "\n",
      "\n",
      "----######   Merging with category dataset   ######----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ended</th>\n",
       "      <td>5123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upcoming</th>\n",
       "      <td>2054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trading</th>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-Sale Ended</th>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Active</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pre-Sale</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Status\n",
       "Ended             5123\n",
       "Upcoming          2054\n",
       "Trading            727\n",
       "Pre-Sale Ended     454\n",
       "Active             167\n",
       "Pre-Sale            70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Total rows: 8595\n",
      "\n",
      "   - Data saved in .\\Results\\01g_ICOmarks_ico_list_scraped_formatted.csv\n",
      "   - Pickle saved in .\\Checkpoints\\formatted_df.pkl\n",
      "   - Stats saved in .\\Results\\01g_ICOmarks_ico_list_scraped_formatted_Stats.csv\n",
      "    - 2 columns excluded: Platform, AcceptedCurr\n",
      "\n",
      "\n",
      "Total elapsed time: 0:04:38\n"
     ]
    }
   ],
   "source": [
    "pkl_path=os.path.join(CHECKPOINT_FOLDER, 'scrape_df_raw.pkl')\n",
    "scrape_df=joblib.load(pkl_path)\n",
    "\n",
    "start=timer()\n",
    "\n",
    "#### extract from raw data\n",
    "print('----######   Extracting information from raw scraped data   ######----\\n')\n",
    "format_df=extract_scaping_icomarks(scrape_df).reset_index(drop=True)\n",
    "\n",
    "pkl_path=os.path.join(CHECKPOINT_FOLDER, 'scrape_df_extracted.pkl')\n",
    "joblib.dump(format_df, pkl_path, compress=('lzma', 3))\n",
    "print(f'\\n   - Data saved in {pkl_path}')\n",
    "\n",
    "\n",
    "#### format nested column and merge with cat_list dataset\n",
    "cat_list=pd.read_csv(os.path.join(RESULTS_FOLDER, '01b_ICOmarks_ico_list_merged.csv'), sep=';')\n",
    "print('\\n\\n\\n----######   Formatting columns   ######----')\n",
    "if len(cat_list) != len(format_df):\n",
    "    raise ValueError('\\n\\n ########### Error: \"cat_list\" and \"format_df\" must have same rows')\n",
    "format_df_rows=format_df.shape[0]\n",
    "format_df=format_columns(format_df, cat_list=cat_list, format_df_rows=format_df_rows, results_folder=RESULTS_FOLDER)\n",
    "print('\\n\\n\\n----######   Merging with category dataset   ######----')\n",
    "cat_list_rows=cat_list.shape[0]\n",
    "final_df=cat_list.copy().merge(format_df, on='url', how='left')\n",
    "final_df['WebsiteUrl']=final_df['WebsiteUrl'].str.replace('?utm_source=icomarks', '', regex=False)\n",
    "display(final_df['Status'].value_counts().to_frame())\n",
    "print(f'   - Total rows: {len(final_df)}')\n",
    "if final_df.shape[0] != cat_list_rows:\n",
    "    print('########## \"final_df\" expected rows do not match')\n",
    "# save file\n",
    "save_path=os.path.join(RESULTS_FOLDER, '01g_ICOmarks_ico_list_scraped_formatted.csv')\n",
    "save_path_pkl=os.path.join(CHECKPOINT_FOLDER, 'formatted_df.pkl')\n",
    "final_df.to_csv(save_path, index=False, sep=';')\n",
    "final_df.to_pickle(save_path_pkl, protocol=-1)\n",
    "print(f'\\n   - Data saved in {save_path}')\n",
    "print(f'   - Pickle saved in {save_path_pkl}')\n",
    "# save stats\n",
    "save_path=os.path.join(RESULTS_FOLDER, '01g_ICOmarks_ico_list_scraped_formatted_Stats.csv')\n",
    "print(f'   - Stats saved in {save_path}')\n",
    "summary_stats(final_df).to_csv(save_path, index=False, sep=';')\n",
    "\n",
    "print('\\n\\nTotal elapsed time:', str(datetime.timedelta(seconds=round(timer()-start))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d71bc9",
   "metadata": {},
   "source": [
    "## Extract Market Price and Social Users list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af40328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_path=os.path.join(CHECKPOINT_FOLDER, 'scrape_df_raw.pkl')\n",
    "scrape_df=joblib.load(pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9af75f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Downloaded Market Price: 724  Total rows: 335746\n",
      "   - Data saved in .\\Results\\01h_ICOmarks_market_price_series.csv\n",
      "   - Pickle saved in .\\Checkpoints\\ICOmarks_market_price_series.pkl\n",
      "\n",
      "- Downloaded Social Users: 6415  Total rows: 7276539\n",
      "   - Data saved in .\\Results\\01h_ICOmarks_social_users_series.csv\n",
      "   - Pickle saved in .\\Checkpoints\\ICOmarks_social_users_series.pkl\n",
      "\n",
      "\n",
      "Total elapsed time: 0:19:02\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "price_df=pd.DataFrame()\n",
    "social_df=pd.DataFrame()\n",
    "for index, row in scrape_df.iterrows():\n",
    "    \n",
    "    # price\n",
    "    if row['MarketPriceSeriesStatus'] == 'DOWNLOADED':\n",
    "        tt=row['MarketPriceSeries'].copy()\n",
    "        tt.insert(0, 'url', row['url'])\n",
    "        price_df=pd.concat([price_df, tt])\n",
    "    \n",
    "    # social users\n",
    "    if row['SocialSeriesStatus'] == 'DOWNLOADED':\n",
    "        tt=pd.DataFrame()\n",
    "        for social_name, social_data in row['SocialBlock'][0]['timeseries'].items():\n",
    "            df=social_data.copy()\n",
    "            df.insert(0, 'Social', social_name)\n",
    "            df.insert(0, 'url', row['url'])\n",
    "            tt=pd.concat([tt, df])\n",
    "        social_df=pd.concat([social_df, tt])\n",
    "     \n",
    "tot_url=price_df['url'].nunique()\n",
    "print(f'- Downloaded Market Price: {tot_url}  Total rows: {len(price_df)}')\n",
    "save_path=os.path.join(RESULTS_FOLDER, '01h_ICOmarks_market_price_series.csv')\n",
    "save_path_pkl=os.path.join(CHECKPOINT_FOLDER, 'ICOmarks_market_price_series.pkl')\n",
    "price_df.to_csv(save_path, index=False, sep=';')\n",
    "price_df.to_pickle(save_path_pkl, protocol=-1)\n",
    "print(f'   - Data saved in {save_path}')\n",
    "print(f'   - Pickle saved in {save_path_pkl}')\n",
    "\n",
    "\n",
    "tot_url=social_df['url'].nunique()\n",
    "print(f'\\n- Downloaded Social Users: {tot_url}  Total rows: {len(social_df)}')\n",
    "save_path=os.path.join(RESULTS_FOLDER, '01h_ICOmarks_social_users_series.csv')\n",
    "save_path_pkl=os.path.join(CHECKPOINT_FOLDER, 'ICOmarks_social_users_series.pkl')\n",
    "# social_df.to_csv(save_path, index=False, sep=';')\n",
    "social_df.to_pickle(save_path_pkl, protocol=-1)\n",
    "print(f'   - Data saved in {save_path}')\n",
    "print(f'   - Pickle saved in {save_path_pkl}')\n",
    "print('\\n\\nTotal elapsed time:', str(datetime.timedelta(seconds=round(timer()-start))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ICO)",
   "language": "python",
   "name": "ico"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
